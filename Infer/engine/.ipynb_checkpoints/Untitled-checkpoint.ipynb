{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57ca8f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from  fine_network import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e730636b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully> ------- fine_model load successful\n",
      "model time: 8.537387371063232\n"
     ]
    }
   ],
   "source": [
    "model = get_fine_model(path='fine_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "123df605",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptflops import get_model_complexity_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8670db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "# from model.attention.SelfAttention import ScaledDotProductAttention\n",
    "# from model.attention.SimplifiedSelfAttention import SimplifiedScaledDotProductAttention\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "\n",
    "class ScaledDotProductAttention(nn.Module):\n",
    "    '''\n",
    "    Scaled dot-product attention\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model, d_k, d_v, h,dropout=.1):\n",
    "        '''\n",
    "        :param d_model: Output dimensionality of the model\n",
    "        :param d_k: Dimensionality of queries and keys\n",
    "        :param d_v: Dimensionality of values\n",
    "        :param h: Number of heads\n",
    "        '''\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.fc_q = nn.Linear(d_model, h * d_k)\n",
    "        self.fc_k = nn.Linear(d_model, h * d_k)\n",
    "        self.fc_v = nn.Linear(d_model, h * d_v)\n",
    "        self.fc_o = nn.Linear(h * d_v, d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_k\n",
    "        self.d_v = d_v\n",
    "        self.h = h\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n",
    "        '''\n",
    "        Computes\n",
    "        :param queries: Queries (b_s, nq, d_model)\n",
    "        :param keys: Keys (b_s, nk, d_model)\n",
    "        :param values: Values (b_s, nk, d_model)\n",
    "        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n",
    "        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n",
    "        :return:\n",
    "        '''\n",
    "        b_s, nq = queries.shape[:2]\n",
    "        nk = keys.shape[1]\n",
    "\n",
    "        q = self.fc_q(queries).view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n",
    "        k = self.fc_k(keys).view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n",
    "        v = self.fc_v(values).view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n",
    "\n",
    "        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n",
    "        if attention_weights is not None:\n",
    "            att = att * attention_weights\n",
    "        if attention_mask is not None:\n",
    "            att = att.masked_fill(attention_mask, -np.inf)\n",
    "        att = torch.softmax(att, -1)\n",
    "        att=self.dropout(att)\n",
    "\n",
    "        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n",
    "        out = self.fc_o(out)  # (b_s, nq, d_model)\n",
    "        return out\n",
    "\n",
    "\n",
    "class SimplifiedScaledDotProductAttention(nn.Module):\n",
    "    '''\n",
    "    Scaled dot-product attention\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model, h,dropout=.1):\n",
    "        '''\n",
    "        :param d_model: Output dimensionality of the model\n",
    "        :param d_k: Dimensionality of queries and keys\n",
    "        :param d_v: Dimensionality of values\n",
    "        :param h: Number of heads\n",
    "        '''\n",
    "        super(SimplifiedScaledDotProductAttention, self).__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model//h\n",
    "        self.d_v = d_model//h\n",
    "        self.h = h\n",
    "\n",
    "        self.fc_o = nn.Linear(h * self.d_v, d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, queries, keys, values, attention_mask=None, attention_weights=None):\n",
    "        '''\n",
    "        Computes\n",
    "        :param queries: Queries (b_s, nq, d_model)\n",
    "        :param keys: Keys (b_s, nk, d_model)\n",
    "        :param values: Values (b_s, nk, d_model)\n",
    "        :param attention_mask: Mask over attention values (b_s, h, nq, nk). True indicates masking.\n",
    "        :param attention_weights: Multiplicative weights for attention values (b_s, h, nq, nk).\n",
    "        :return:\n",
    "        '''\n",
    "        b_s, nq = queries.shape[:2]\n",
    "        nk = keys.shape[1]\n",
    "\n",
    "        q = queries.view(b_s, nq, self.h, self.d_k).permute(0, 2, 1, 3)  # (b_s, h, nq, d_k)\n",
    "        k = keys.view(b_s, nk, self.h, self.d_k).permute(0, 2, 3, 1)  # (b_s, h, d_k, nk)\n",
    "        v = values.view(b_s, nk, self.h, self.d_v).permute(0, 2, 1, 3)  # (b_s, h, nk, d_v)\n",
    "\n",
    "        att = torch.matmul(q, k) / np.sqrt(self.d_k)  # (b_s, h, nq, nk)\n",
    "        if attention_weights is not None:\n",
    "            att = att * attention_weights\n",
    "        if attention_mask is not None:\n",
    "            att = att.masked_fill(attention_mask, -np.inf)\n",
    "        att = torch.softmax(att, -1)\n",
    "        att=self.dropout(att)\n",
    "\n",
    "        out = torch.matmul(att, v).permute(0, 2, 1, 3).contiguous().view(b_s, nq, self.h * self.d_v)  # (b_s, nq, h*d_v)\n",
    "        out = self.fc_o(out)  # (b_s, nq, d_model)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############-----------------------------------------------------------------------------############\n",
    "\n",
    "\n",
    "class PositionAttentionModule(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model=512,kernel_size=3,H=7,W=7,D=7):\n",
    "        super().__init__()\n",
    "        self.cnn=nn.Conv3d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-1)//2)\n",
    "        self.pa=ScaledDotProductAttention(d_model,d_k=d_model,d_v=d_model,h=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b,c,h,w,d=x.shape\n",
    "        y=self.cnn(x)\n",
    "        y=y.view(b,c,-1).permute(0,2,1) #bs,h*w,c\n",
    "        y=self.pa(y,y,y) #bs,h*w,c\n",
    "        return y\n",
    "\n",
    "\n",
    "class ChannelAttentionModule(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model=512,kernel_size=3,H=7,W=7,D=7):\n",
    "        super().__init__()\n",
    "        self.cnn=nn.Conv3d(d_model,d_model,kernel_size=kernel_size,padding=(kernel_size-1)//2)\n",
    "        self.pa=SimplifiedScaledDotProductAttention(H*W*D,h=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        b,c,h,w,d=x.shape\n",
    "        y=self.cnn(x)\n",
    "        y=y.view(b,c,-1) #bs,c,h*w\n",
    "        y=self.pa(y,y,y) #bs,c,h*w\n",
    "        return y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DAModule(nn.Module):\n",
    "\n",
    "    def __init__(self,d_model=512,kernel_size=3,H=7,W=7,D=7):\n",
    "        super().__init__()\n",
    "        self.position_attention_module=PositionAttentionModule(d_model=d_model,kernel_size=3,H=H,W=W,D=D)\n",
    "        self.channel_attention_module=ChannelAttentionModule(d_model=d_model,kernel_size=3,H=H,W=W,D=D)\n",
    "    \n",
    "    def forward(self,input):\n",
    "        bs,c,h,w,d=input.shape\n",
    "        p_out=self.position_attention_module(input)\n",
    "        c_out=self.channel_attention_module(input)\n",
    "        p_out=p_out.permute(0,2,1).view(bs,c,h,w,d)\n",
    "        c_out=c_out.view(bs,c,h,w,d)\n",
    "        return p_out+c_out\n",
    "\n",
    "\n",
    "from copy import deepcopy\n",
    "from nnunet.utilities.nd_softmax import softmax_helper\n",
    "from torch import nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from nnunet.network_architecture.initialization import InitWeights_He\n",
    "from nnunet.network_architecture.neural_network import SegmentationNetwork\n",
    "import torch.nn.functional     \n",
    "       \n",
    "class Stem(nn.Module):\n",
    "    \"\"\"\n",
    "    fixes a bug in ConvDropoutNormNonlin where lrelu was used regardless of nonlin. Bad.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels,\n",
    "                 conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "                 norm_op=nn.InstanceNorm3d, norm_op_kwargs=None,\n",
    "                 dropout_op=nn.Dropout3d, dropout_op_kwargs=None,\n",
    "                 nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super().__init__()\n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if dropout_op_kwargs is None:\n",
    "            dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout_op = dropout_op\n",
    "        self.dropout_op_kwargs = dropout_op_kwargs\n",
    "        self.norm_op_kwargs = norm_op_kwargs\n",
    "        self.conv_kwargs = conv_kwargs\n",
    "        self.conv_op = conv_op\n",
    "        self.norm_op = norm_op\n",
    "\n",
    "        self.conv = self.conv_op(input_channels, output_channels, **self.conv_kwargs)\n",
    "        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs[\n",
    "            'p'] > 0:\n",
    "            self.dropout = self.dropout_op(**self.dropout_op_kwargs)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.instnorm = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        return self.lrelu(self.instnorm(x))\n",
    "    \n",
    "class Block(nn.Module):\n",
    "    \"\"\"\n",
    "    fixes a bug in ConvDropoutNormNonlin where lrelu was used regardless of nonlin. Bad.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels,\n",
    "                 conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "                 norm_op=nn.InstanceNorm3d, norm_op_kwargs=None,\n",
    "                 dropout_op=nn.Dropout3d, dropout_op_kwargs=None,\n",
    "                 nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super().__init__()\n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if dropout_op_kwargs is None:\n",
    "            dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout_op = dropout_op\n",
    "        self.dropout_op_kwargs = dropout_op_kwargs\n",
    "        self.norm_op_kwargs = norm_op_kwargs\n",
    "        self.conv_kwargs = conv_kwargs\n",
    "        self.conv_op = conv_op\n",
    "        self.norm_op = norm_op\n",
    "\n",
    "        self.conv = self.conv_op(input_channels, output_channels, **self.conv_kwargs)\n",
    "        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs[\n",
    "            'p'] > 0:\n",
    "            self.dropout = self.dropout_op(**self.dropout_op_kwargs)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.instnorm = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "        \n",
    "                \n",
    "        self.stride = conv_kwargs['stride']\n",
    "        conv_kwargs = {'kernel_size': 1, 'stride':self.stride, 'padding': 0, 'dilation': 1, 'bias': True}\n",
    "        \n",
    "        self.convbn1x1 = nn.Sequential(nn.Conv3d(input_channels,output_channels,**conv_kwargs),\n",
    "                                self.norm_op(output_channels, **self.norm_op_kwargs))\n",
    "        if self.stride == 1:\n",
    "            self.identity_bn = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        indentity = x\n",
    "        x = self.conv(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "        x = self.instnorm(x)\n",
    "        \n",
    "                    \n",
    "        if self.stride == 1:\n",
    "            indentity = self.convbn1x1(indentity)+self.identity_bn(indentity)\n",
    "        else:\n",
    "            indentity = self.convbn1x1(indentity)\n",
    "        x = x+indentity\n",
    "        return self.lrelu(x)\n",
    "        \n",
    "class ResVGG_Backbone(nn.Module):\n",
    "    def __init__(self, in_channels = 1, image_size = [96,96,96], channels = [32,64,128,256,320,320]):\n",
    "        super().__init__()\n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "        #feature block\n",
    "        self.blocks = []\n",
    "        self.blocks.append(self.make_stage(in_channels,channels[0],Stem,stride=1))\n",
    "        in_channels = channels[0]\n",
    "        for index in range(len(channels)-1):\n",
    "            self.blocks.append(self.make_stage(in_channels,channels[index+1],Block,stride=2))\n",
    "            in_channels = channels[index+1]\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.blocks = nn.ModuleList(self.blocks)\n",
    "        \n",
    "#         self.atten = DAModule(self.channels[index],H=self.sizes[-2][0],W=self.sizes[-2][1],D=self.sizes[-2][2])\n",
    "    def make_stage(self,in_channels,output_channels,block,stride=1):\n",
    "        conv_kwargs1 = {'kernel_size': 3, 'stride': stride, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "        return nn.Sequential(\n",
    "                    block( #extract features\n",
    "                        input_channels=in_channels,output_channels=output_channels,\n",
    "                    conv_kwargs = conv_kwargs1),\n",
    "                    block( #dowm sampling\n",
    "                        input_channels=output_channels,output_channels=output_channels,\n",
    "                        ))\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            out.append(x)\n",
    "        out.pop()\n",
    "        return out[::-1],x\n",
    "    \n",
    "class ConvDropoutNormNonlin(nn.Module):\n",
    "    \"\"\"\n",
    "    fixes a bug in ConvDropoutNormNonlin where lrelu was used regardless of nonlin. Bad.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_channels, output_channels,\n",
    "                 conv_op=nn.Conv3d, conv_kwargs=None,\n",
    "                 norm_op=nn.InstanceNorm3d, norm_op_kwargs=None,\n",
    "                 dropout_op=nn.Dropout3d, dropout_op_kwargs=None,\n",
    "                 nonlin=nn.LeakyReLU, nonlin_kwargs=None):\n",
    "        super(ConvDropoutNormNonlin, self).__init__()\n",
    "        if nonlin_kwargs is None:\n",
    "            nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        if dropout_op_kwargs is None:\n",
    "            dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "        if norm_op_kwargs is None:\n",
    "            norm_op_kwargs = {'eps': 1e-5, 'affine': True, 'momentum': 0.1}\n",
    "        if conv_kwargs is None:\n",
    "            conv_kwargs = {'kernel_size': 3, 'stride': 1, 'padding': 1, 'dilation': 1, 'bias': True}\n",
    "\n",
    "        self.nonlin_kwargs = nonlin_kwargs\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout_op = dropout_op\n",
    "        self.dropout_op_kwargs = dropout_op_kwargs\n",
    "        self.norm_op_kwargs = norm_op_kwargs\n",
    "        self.conv_kwargs = conv_kwargs\n",
    "        self.conv_op = conv_op\n",
    "        self.norm_op = norm_op\n",
    "\n",
    "        self.conv = self.conv_op(input_channels, output_channels, **self.conv_kwargs)\n",
    "        if self.dropout_op is not None and self.dropout_op_kwargs['p'] is not None and self.dropout_op_kwargs[\n",
    "            'p'] > 0:\n",
    "            self.dropout = self.dropout_op(**self.dropout_op_kwargs)\n",
    "        else:\n",
    "            self.dropout = None\n",
    "        self.instnorm = self.norm_op(output_channels, **self.norm_op_kwargs)\n",
    "        self.lrelu = self.nonlin(**self.nonlin_kwargs)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv(x)\n",
    "        if self.dropout is not None:\n",
    "            x = self.dropout(x)\n",
    "\n",
    "        return self.lrelu(self.instnorm(x))\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels = 1, image_size = [96,96,96], channels = [32,64,128,256,320,320]):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tu = []\n",
    "        for channel in range(1,len(channels)):\n",
    "            in_channel,out_channel = channels[-(channel)],channels[-(channel+1)]\n",
    "            self.tu.append(nn.ConvTranspose3d(in_channel,out_channel,kernel_size=2, stride=2\n",
    "        ))\n",
    "        self.decoders = []\n",
    "        decoders_channels = channels[:-1]\n",
    "        for channel in range(1,len(decoders_channels)+1):\n",
    "            in_channel = decoders_channels[-(channel)]\n",
    "            self.decoders.append(nn.Sequential(\n",
    "            ConvDropoutNormNonlin( #extract features\n",
    "                        input_channels=in_channel*2,output_channels=in_channel),\n",
    "            ConvDropoutNormNonlin( #extract features\n",
    "                        input_channels=in_channel,output_channels=in_channel)\n",
    "            ))\n",
    "        self.decoders = nn.ModuleList(self.decoders)\n",
    "        self.tu = nn.ModuleList(self.tu)\n",
    "    def forward(self,x,skips):\n",
    "        index = [0,1,2,3,4]\n",
    "        for i,up,decode in zip(index,self.tu,self.decoders):\n",
    "            x = up(x)\n",
    "            x = decode(torch.cat((x,skips[i]),1))\n",
    "        return x\n",
    "class UNet(nn.Module):\n",
    "\n",
    "    def __init__(self,in_channels = 4,num_classes=3, image_size = [96,96,96], channels = [32,64,128,256,320,320]):\n",
    "        super().__init__()\n",
    "        self.backbone = ResVGG_Backbone(in_channels = in_channels, image_size = image_size, channels = channels)\n",
    "        self.decoder = Decoder(in_channels = in_channels, image_size = image_size, channels = channels)\n",
    "        self.logits = nn.Conv3d(channels[0],num_classes,1,1)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        skips,feature = self.backbone(x)\n",
    "        x = self.decoder(feature,skips)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21dce853",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14a29c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  31.72 M, 100.000% Params, 542.69 GMac, 100.000% MACs, \n",
      "  (backbone): ResVGG_Backbone(\n",
      "    14.55 M, 45.879% Params, 148.05 GMac, 27.281% MACs, \n",
      "    (blocks): ModuleList(\n",
      "      14.55 M, 45.879% Params, 148.05 GMac, 27.281% MACs, \n",
      "      (0): Sequential(\n",
      "        31.3 k, 0.099% Params, 65.77 GMac, 12.119% MACs, \n",
      "        (0): Stem(\n",
      "          3.55 k, 0.011% Params, 7.52 GMac, 1.385% MACs, \n",
      "          (conv): Conv3d(3.49 k, 0.011% Params, 7.31 GMac, 1.348% MACs, 4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, 0.000% Params, 134.22 MMac, 0.025% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 67.11 MMac, 0.012% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): Stem(\n",
      "          27.74 k, 0.087% Params, 58.25 GMac, 10.734% MACs, \n",
      "          (conv): Conv3d(27.68 k, 0.087% Params, 58.05 GMac, 10.697% MACs, 32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, 0.000% Params, 134.22 MMac, 0.025% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 67.11 MMac, 0.012% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        172.93 k, 0.545% Params, 45.37 GMac, 8.359% MACs, \n",
      "        (0): Block(\n",
      "          57.73 k, 0.182% Params, 15.15 GMac, 2.792% MACs, \n",
      "          (conv): Conv3d(55.36 k, 0.175% Params, 14.51 GMac, 2.674% MACs, 32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 16.78 MMac, 0.003% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            2.24 k, 0.007% Params, 587.2 MMac, 0.108% MACs, \n",
      "            (0): Conv3d(2.11 k, 0.007% Params, 553.65 MMac, 0.102% MACs, 32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "            (1): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          115.2 k, 0.363% Params, 30.22 GMac, 5.568% MACs, \n",
      "          (conv): Conv3d(110.66 k, 0.349% Params, 29.01 GMac, 5.345% MACs, 64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 16.78 MMac, 0.003% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            4.29 k, 0.014% Params, 1.12 GMac, 0.207% MACs, \n",
      "            (0): Conv3d(4.16 k, 0.013% Params, 1.09 GMac, 0.201% MACs, 64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "          (identity_bn): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        689.92 k, 2.175% Params, 22.62 GMac, 4.167% MACs, \n",
      "        (0): Block(\n",
      "          230.14 k, 0.725% Params, 7.55 GMac, 1.390% MACs, \n",
      "          (conv): Conv3d(221.31 k, 0.698% Params, 7.25 GMac, 1.336% MACs, 64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 4.19 MMac, 0.001% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            8.58 k, 0.027% Params, 281.02 MMac, 0.052% MACs, \n",
      "            (0): Conv3d(8.32 k, 0.026% Params, 272.63 MMac, 0.050% MACs, 64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "            (1): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          459.78 k, 1.449% Params, 15.07 GMac, 2.777% MACs, \n",
      "          (conv): Conv3d(442.5 k, 1.395% Params, 14.5 GMac, 2.672% MACs, 128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 4.19 MMac, 0.001% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            16.77 k, 0.053% Params, 549.45 MMac, 0.101% MACs, \n",
      "            (0): Conv3d(16.51 k, 0.052% Params, 541.07 MMac, 0.100% MACs, 128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "          (identity_bn): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        2.76 M, 8.688% Params, 11.29 GMac, 2.081% MACs, \n",
      "        (0): Block(\n",
      "          919.04 k, 2.897% Params, 3.77 GMac, 0.694% MACs, \n",
      "          (conv): Conv3d(884.99 k, 2.790% Params, 3.62 GMac, 0.668% MACs, 128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            33.54 k, 0.106% Params, 137.36 MMac, 0.025% MACs, \n",
      "            (0): Conv3d(33.02 k, 0.104% Params, 135.27 MMac, 0.025% MACs, 128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "            (1): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          1.84 M, 5.791% Params, 7.53 GMac, 1.387% MACs, \n",
      "          (conv): Conv3d(1.77 M, 5.579% Params, 7.25 GMac, 1.336% MACs, 256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            66.3 k, 0.209% Params, 271.58 MMac, 0.050% MACs, \n",
      "            (0): Conv3d(65.79 k, 0.207% Params, 269.48 MMac, 0.050% MACs, 256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "          (identity_bn): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        5.17 M, 16.283% Params, 2.65 GMac, 0.487% MACs, \n",
      "        (0): Block(\n",
      "          2.3 M, 7.237% Params, 1.18 GMac, 0.217% MACs, \n",
      "          (conv): Conv3d(2.21 M, 6.973% Params, 1.13 GMac, 0.209% MACs, 256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 163.84 KMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            82.88 k, 0.261% Params, 42.43 MMac, 0.008% MACs, \n",
      "            (0): Conv3d(82.24 k, 0.259% Params, 42.11 MMac, 0.008% MACs, 256, 320, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "            (1): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          2.87 M, 9.046% Params, 1.47 GMac, 0.271% MACs, \n",
      "          (conv): Conv3d(2.77 M, 8.716% Params, 1.42 GMac, 0.261% MACs, 320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 163.84 KMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            103.36 k, 0.326% Params, 52.92 MMac, 0.010% MACs, \n",
      "            (0): Conv3d(102.72 k, 0.324% Params, 52.59 MMac, 0.010% MACs, 320, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "          (identity_bn): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "      (5): Sequential(\n",
      "        5.74 M, 18.090% Params, 367.33 MMac, 0.068% MACs, \n",
      "        (0): Block(\n",
      "          2.87 M, 9.044% Params, 183.64 MMac, 0.034% MACs, \n",
      "          (conv): Conv3d(2.77 M, 8.716% Params, 176.97 MMac, 0.033% MACs, 320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(640, 0.002% Params, 40.96 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 20.48 KMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            103.36 k, 0.326% Params, 6.62 MMac, 0.001% MACs, \n",
      "            (0): Conv3d(102.72 k, 0.324% Params, 6.57 MMac, 0.001% MACs, 320, 320, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
      "            (1): InstanceNorm3d(640, 0.002% Params, 40.96 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "        )\n",
      "        (1): Block(\n",
      "          2.87 M, 9.046% Params, 183.69 MMac, 0.034% MACs, \n",
      "          (conv): Conv3d(2.77 M, 8.716% Params, 176.97 MMac, 0.033% MACs, 320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(640, 0.002% Params, 40.96 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 20.48 KMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "          (convbn1x1): Sequential(\n",
      "            103.36 k, 0.326% Params, 6.62 MMac, 0.001% MACs, \n",
      "            (0): Conv3d(102.72 k, 0.324% Params, 6.57 MMac, 0.001% MACs, 320, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "            (1): InstanceNorm3d(640, 0.002% Params, 40.96 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          )\n",
      "          (identity_bn): InstanceNorm3d(640, 0.002% Params, 40.96 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    17.17 M, 54.120% Params, 394.43 GMac, 72.681% MACs, \n",
      "    (decoders): ModuleList(\n",
      "      15.35 M, 48.385% Params, 331.11 GMac, 61.013% MACs, \n",
      "      (0): Sequential(\n",
      "        8.3 M, 26.152% Params, 4.25 GMac, 0.783% MACs, \n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          5.53 M, 17.434% Params, 2.83 GMac, 0.522% MACs, \n",
      "          (conv): Conv3d(5.53 M, 17.432% Params, 2.83 GMac, 0.522% MACs, 640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 163.84 KMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          2.77 M, 8.718% Params, 1.42 GMac, 0.261% MACs, \n",
      "          (conv): Conv3d(2.77 M, 8.716% Params, 1.42 GMac, 0.261% MACs, 320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(640, 0.002% Params, 327.68 KMac, 0.000% MACs, 320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 163.84 KMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Sequential(\n",
      "        5.31 M, 16.738% Params, 21.75 GMac, 4.008% MACs, \n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          3.54 M, 11.158% Params, 14.5 GMac, 2.672% MACs, \n",
      "          (conv): Conv3d(3.54 M, 11.156% Params, 14.5 GMac, 2.671% MACs, 512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          1.77 M, 5.580% Params, 7.25 GMac, 1.336% MACs, \n",
      "          (conv): Conv3d(1.77 M, 5.579% Params, 7.25 GMac, 1.336% MACs, 256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(512, 0.002% Params, 2.1 MMac, 0.000% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 1.05 MMac, 0.000% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Sequential(\n",
      "        1.33 M, 4.186% Params, 43.52 GMac, 8.019% MACs, \n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          885.12 k, 2.790% Params, 29.01 GMac, 5.345% MACs, \n",
      "          (conv): Conv3d(884.86 k, 2.789% Params, 29.0 GMac, 5.343% MACs, 256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 4.19 MMac, 0.001% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          442.75 k, 1.396% Params, 14.51 GMac, 2.674% MACs, \n",
      "          (conv): Conv3d(442.5 k, 1.395% Params, 14.5 GMac, 2.672% MACs, 128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(256, 0.001% Params, 8.39 MMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 4.19 MMac, 0.001% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): Sequential(\n",
      "        332.16 k, 1.047% Params, 87.11 GMac, 16.051% MACs, \n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          221.38 k, 0.698% Params, 58.05 GMac, 10.697% MACs, \n",
      "          (conv): Conv3d(221.25 k, 0.697% Params, 58.0 GMac, 10.687% MACs, 128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 16.78 MMac, 0.003% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          110.78 k, 0.349% Params, 29.06 GMac, 5.354% MACs, \n",
      "          (conv): Conv3d(110.66 k, 0.349% Params, 29.01 GMac, 5.345% MACs, 64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(128, 0.000% Params, 33.55 MMac, 0.006% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 16.78 MMac, 0.003% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): Sequential(\n",
      "        83.14 k, 0.262% Params, 174.48 GMac, 32.151% MACs, \n",
      "        (0): ConvDropoutNormNonlin(\n",
      "          55.39 k, 0.175% Params, 116.23 GMac, 21.418% MACs, \n",
      "          (conv): Conv3d(55.33 k, 0.174% Params, 116.03 GMac, 21.381% MACs, 64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, 0.000% Params, 134.22 MMac, 0.025% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 67.11 MMac, 0.012% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "        (1): ConvDropoutNormNonlin(\n",
      "          27.74 k, 0.087% Params, 58.25 GMac, 10.734% MACs, \n",
      "          (conv): Conv3d(27.68 k, 0.087% Params, 58.05 GMac, 10.697% MACs, 32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "          (instnorm): InstanceNorm3d(64, 0.000% Params, 134.22 MMac, 0.025% MACs, 32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "          (lrelu): LeakyReLU(0, 0.000% Params, 67.11 MMac, 0.012% MACs, negative_slope=0.01, inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (tu): ModuleList(\n",
      "      1.82 M, 5.735% Params, 63.32 GMac, 11.668% MACs, \n",
      "      (0): ConvTranspose3d(819.52 k, 2.583% Params, 419.59 MMac, 0.077% MACs, 320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      (1): ConvTranspose3d(655.62 k, 2.067% Params, 2.69 GMac, 0.495% MACs, 320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      (2): ConvTranspose3d(262.27 k, 0.827% Params, 8.59 GMac, 1.584% MACs, 256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      (3): ConvTranspose3d(65.6 k, 0.207% Params, 17.2 GMac, 3.169% MACs, 128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "      (4): ConvTranspose3d(16.42 k, 0.052% Params, 34.43 GMac, 6.344% MACs, 64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
      "    )\n",
      "  )\n",
      "  (logits): Conv3d(99, 0.000% Params, 207.62 MMac, 0.038% MACs, 32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      ")\n",
      "542.69 GMac 31.72 M\n"
     ]
    }
   ],
   "source": [
    "flops, params = get_model_complexity_info(model, (4,128,128,128), as_strings=True, print_per_layer_stat=True)\n",
    "print(flops, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f044f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (backbone): ResVGG_Backbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Stem(\n",
       "          (conv): Conv3d(4, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (1): Stem(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Block(\n",
       "          (conv): Conv3d(32, 64, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "            (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            (1): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "          (identity_bn): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Block(\n",
       "          (conv): Conv3d(64, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "            (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(128, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            (1): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "          (identity_bn): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Block(\n",
       "          (conv): Conv3d(128, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "            (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(256, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            (1): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "          (identity_bn): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Block(\n",
       "          (conv): Conv3d(256, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(256, 320, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "            (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(320, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "          (identity_bn): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Block(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(320, 320, kernel_size=(1, 1, 1), stride=(2, 2, 2))\n",
       "            (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "          (convbn1x1): Sequential(\n",
       "            (0): Conv3d(320, 320, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "            (1): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          )\n",
       "          (identity_bn): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoders): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(640, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (1): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(320, 320, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(512, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (1): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(256, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (1): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(128, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (1): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(64, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "        (1): ConvDropoutNormNonlin(\n",
       "          (conv): Conv3d(32, 32, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
       "          (instnorm): InstanceNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
       "          (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (tu): ModuleList(\n",
       "      (0): ConvTranspose3d(320, 320, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (1): ConvTranspose3d(320, 256, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (2): ConvTranspose3d(256, 128, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (3): ConvTranspose3d(128, 64, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "      (4): ConvTranspose3d(64, 32, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "  )\n",
       "  (logits): Conv3d(32, 3, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd153d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
